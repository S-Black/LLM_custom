{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your own custom fine tuned chat bot with your own data\n",
    "\n",
    "You need your own OpenAI API key which might cost you money.\n",
    "You will also need an API key for Telegram and your user ID to limit the chatbot use to your bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import telebot\n",
    "from llama_index import GPTVectorStoreIndex, download_loader, StorageContext, load_index_from_storage, LLMPredictor,ServiceContext\n",
    "from langchain import OpenAI,ChatOpenAI\n",
    "from telegram import Update\n",
    "from telegram.ext import filters, MessageHandler, ApplicationBuilder, CommandHandler, ContextTypes\n",
    "\n",
    "#needed because of neverending loop\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'your_key_here'\n",
    "Telegram_API_key = 'your telegram key here'\n",
    "telegram_user_id = 12345 #Enter your telegram user id here to limit bot use to yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create index\n",
    "def create_index():\n",
    "    SimpleDirectoryReader = download_loader(\"SimpleDirectoryReader\")\n",
    "\n",
    "    loader = SimpleDirectoryReader('./Data', recursive=True, exclude_hidden=True)\n",
    "    documents = loader.load_data()\n",
    "    \n",
    "    # define LLM\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\",max_tokens=512)) #\"gpt-3.5-turbo\",\"text-davinci-003\"\n",
    "\n",
    "    # configure service context\n",
    "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "\n",
    "    index = GPTVectorStoreIndex.from_documents(documents,service_context=service_context)\n",
    "    query_engine = index.as_query_engine()\n",
    "    #store index (not working at the moment)\n",
    "    #index.storage_context.persist('./storage')\n",
    "    return query_engine\n",
    "query_engine = create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test response\n",
    "query_engine.query('Hallo World').response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    #Initialise your bot with a welcome message\n",
    "    await context.bot.send_message(chat_id=update.effective_chat.id, text=\"I'm a bot, please talk to me!\")\n",
    "\n",
    "async def bot(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    if update.message.from_user.id==telegram_user_id:\n",
    "        #generate response from message text\n",
    "        response = query_engine.query(update.message.text).response\n",
    "        #chunk up response in case it's too big\n",
    "        chunks = [response[i:i+4096] for i in range(0, len(response), 4096)]\n",
    "        # Loop through the chunks and send them to the bot\n",
    "        for chunk in chunks:\n",
    "            await context.bot.send_message(chat_id=update.effective_chat.id, text=chunk)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def run_bot(query_engine):\n",
    "    application = ApplicationBuilder().token(Telegram_API_key).build()\n",
    "\n",
    "    start_handler = CommandHandler('start', start)\n",
    "    llm_handler = MessageHandler(filters.TEXT & (~filters.COMMAND), bot)\n",
    "    \n",
    "    application.add_handler(start_handler)\n",
    "    application.add_handler(llm_handler)\n",
    "\n",
    "    application.run_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run bot - go to telegram to talk to your bot\n",
    "run_bot(query_engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
